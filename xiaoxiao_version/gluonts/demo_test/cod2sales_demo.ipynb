{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from itertools import islice\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.model.deepar import DeepAREstimator\n",
    "from gluonts.trainer import Trainer\n",
    "from gluonts.dataset.util import to_pandas\n",
    "from gluonts.distribution import NegativeBinomialOutput\n",
    "\n",
    "from demo_utils import *\n",
    "\n",
    "\n",
    "TRAIN_START = '2018-01-01'\n",
    "TRAIN_END = '2019-09-28'\n",
    "TEST_START = '2019-06-28'\n",
    "TEST_END = '2019-11-29'\n",
    "TIME_FRAME = [TRAIN_START, TRAIN_END, TEST_START, TEST_END]\n",
    "\n",
    "\n",
    "sales_df = pd.read_csv('cid2_794_sales.csv')\n",
    "sales_df.fillna({'sale_qtty': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cid3_cnt = len(set(sales_df.cid3))\n",
    "cid3_dict = dict(zip(sorted(set(sales_df.cid3)), range(cid3_cnt)))\n",
    "\n",
    "sales_df = generate_holiday(sales_df, TIME_FRAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_list = sorted(set(sales_df.item_sku_id))\n",
    "train_data, validation_data, test_data = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "sku = sku_list[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147986"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_frame = [TRAIN_START, TRAIN_END, TEST_START, TEST_END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df_sub = sales_df[sales_df.item_sku_id == sku].sort_values('date').reset_index(drop=True)\n",
    "start = sales_df_sub.date[0]\n",
    "cid3 = sales_df_sub.cid3[0]\n",
    "train_start, train_end, test_start, test_end = time_frame\n",
    "decoder_len = date_diff(train_end, test_end) - 1\n",
    "feat_cols = ['item_sku_id', 'date', 'sale_qtty', 'booking_flag', 'booking_pay_flag',\n",
    "             'presale_flag', 'presale_pay_flag', 'instant_flag', 'expose_flag', 'instant_hour',\n",
    "             'instant_price', 'redprice', 'nominal_netprice']\n",
    "sales_df_sub = sales_df_sub[feat_cols]\n",
    "train_data = sales_df_sub[sales_df_sub.date.between(train_start, train_end)]\n",
    "test_data = sales_df_sub[sales_df_sub.date.between(train_start, test_end)]\n",
    "cols_to_drop = ['item_sku_id', 'date', 'sale_qtty']\n",
    "Xtrain, ytrain = train_data.drop(cols_to_drop, axis=1), train_data.sale_qtty.values\n",
    "Xtest, ytest = test_data.drop(cols_to_drop, axis=1), test_data.sale_qtty.values\n",
    "cols_to_normalize = ['instant_price', 'redprice', 'nominal_netprice', 'instant_hour']\n",
    "for col in cols_to_normalize:\n",
    "    temp_mean, temp_std = Xtrain[col].mean(), Xtrain[col].std()\n",
    "    if temp_std < 1e-4:\n",
    "        Xtrain[col] = Xtrain[col] - temp_mean\n",
    "        Xtest[col] = Xtest[col] - temp_mean\n",
    "        continue\n",
    "    Xtrain[col] = (Xtrain[col] - temp_mean) / temp_std\n",
    "    Xtest[col] = (Xtest[col] - temp_mean) / temp_std\n",
    "Xtrain, Xtest = Xtrain.values, Xtest.values\n",
    "train_listdataset = {'start': start,\n",
    "                     'target': ytrain,\n",
    "                     'feat_static_cat': cid3_dict[cid3],\n",
    "                     'feat_dynamic_real': Xtrain.T}\n",
    "\n",
    "validation_listdataset = {'start': start,\n",
    "                          'target': ytest,\n",
    "                          'feat_static_cat': cid3_dict[cid3],\n",
    "                          'feat_dynamic_real': Xtest.T}\n",
    "\n",
    "# test data's target should only contain dates before prediction_length days.\n",
    "# test data's feat_dynamic_real should contain dates for total_length days\n",
    "test_listdataset = {'start': start,\n",
    "                    'target': ytest[:-decoder_len],\n",
    "                    'feat_static_cat': cid3_dict[cid3],\n",
    "                    'feat_dynamic_real': Xtest.T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[]\n",
    "a.append(train_listdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ListDataset(a, freq='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start': Timestamp('2018-01-01 00:00:00', freq='D'),\n",
       "  'target': array([ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  2.,  1.,  1.,  0.,  3.,  2.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "          1.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          1.,  0.,  1.,  6.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          2.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  2.,\n",
       "          1.,  1.,  2.,  0.,  0., 11.,  1.,  0.,  1.,  0.,  1.,  3.,  2.,\n",
       "          0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  1.,  2.,  2.,  1.,  1.,  0.,  2.,  2.,  0.,  0.,  1.,  1.,\n",
       "          1.,  1.,  2.,  0.,  0.,  0.,  1.,  0.,  1.,  2.,  0.,  0.,  0.,\n",
       "          1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,  2.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  2.,  0.,  0.,  0.,  1.,  1.,  0.,\n",
       "          0.,  0.,  0.,  1.,  2.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  1.,  2.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  8.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,\n",
       "          0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,\n",
       "          1.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,\n",
       "          0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "          0.,  0.,  0.,  0.,  2.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  1.,\n",
       "          1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
       "          0.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  2.,  2.,  1.,  0.,\n",
       "          0.,  0.,  2.,  2.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  2.,  0.,\n",
       "          3.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,\n",
       "          1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        dtype=float32),\n",
       "  'feat_static_cat': array([6], dtype=int32),\n",
       "  'feat_dynamic_real': array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 1.647357  ,  1.647357  ,  1.647357  , ..., -1.2539407 ,\n",
       "          -1.2539407 , -1.2539407 ],\n",
       "         [ 1.647357  ,  1.647357  ,  1.647357  , ..., -1.2539407 ,\n",
       "          -1.2539407 , -1.2539407 ],\n",
       "         [ 1.6794103 ,  1.6794103 ,  1.6794103 , ..., -0.76083404,\n",
       "          -0.76083404, -0.76083404]], dtype=float32),\n",
       "  'source': SourceContext(source='list_data', row=1)}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sku_listdataset(sku, sales_df, time_frame, cid3_dict):\n",
    "    sales_df_sub = sales_df[sales_df.item_sku_id == sku].sort_values('date').reset_index(drop=True)\n",
    "    start = sales_df_sub.date[0]\n",
    "    cid3 = sales_df_sub.cid3[0]\n",
    "\n",
    "    train_start, train_end, test_start, test_end = time_frame\n",
    "    decoder_len = date_diff(train_end, test_end) - 1\n",
    "    feat_cols = ['item_sku_id', 'date', 'sale_qtty', 'booking_flag', 'booking_pay_flag',\n",
    "                 'presale_flag', 'presale_pay_flag', 'instant_flag', 'expose_flag', 'instant_hour',\n",
    "                 'instant_price', 'redprice', 'nominal_netprice']\n",
    "    sales_df_sub = sales_df_sub[feat_cols]\n",
    "    train_data = sales_df_sub[sales_df_sub.date.between(train_start, train_end)]\n",
    "    test_data = sales_df_sub[sales_df_sub.date.between(train_start, test_end)]\n",
    "    cols_to_drop = ['item_sku_id', 'date', 'sale_qtty']\n",
    "    Xtrain, ytrain = train_data.drop(cols_to_drop, axis=1), train_data.sale_qtty.values\n",
    "    Xtest, ytest = test_data.drop(cols_to_drop, axis=1), test_data.sale_qtty.values\n",
    "\n",
    "    cols_to_normalize = ['instant_price', 'redprice', 'nominal_netprice', 'instant_hour']\n",
    "    for col in cols_to_normalize:\n",
    "        temp_mean, temp_std = Xtrain[col].mean(), Xtrain[col].std()\n",
    "        if temp_std < 1e-4:\n",
    "            Xtrain[col] = Xtrain[col] - temp_mean\n",
    "            Xtest[col] = Xtest[col] - temp_mean\n",
    "            continue\n",
    "        Xtrain[col] = (Xtrain[col] - temp_mean) / temp_std\n",
    "        Xtest[col] = (Xtest[col] - temp_mean) / temp_std\n",
    "\n",
    "    Xtrain, Xtest = Xtrain.values, Xtest.values\n",
    "\n",
    "    train_listdataset = {'start': start,\n",
    "                         'target': ytrain,\n",
    "                         'feat_static_cat': cid3_dict[cid3],\n",
    "                         'feat_dynamic_real': Xtrain.T}\n",
    "\n",
    "    validation_listdataset = {'start': start,\n",
    "                              'target': ytest,\n",
    "                              'feat_static_cat': cid3_dict[cid3],\n",
    "                              'feat_dynamic_real': Xtest.T}\n",
    "\n",
    "    # test data's target should only contain dates before prediction_length days.\n",
    "    # test data's feat_dynamic_real should contain dates for total_length days\n",
    "    test_listdataset = {'start': start,\n",
    "                        'target': ytest[:-decoder_len],\n",
    "                        'feat_static_cat': cid3_dict[cid3],\n",
    "                        'feat_dynamic_real': Xtest.T}\n",
    "\n",
    "    return train_listdataset, validation_listdataset, test_listdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
