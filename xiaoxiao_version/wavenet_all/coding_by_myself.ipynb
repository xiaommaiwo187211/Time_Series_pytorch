{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class DenseConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size):\n",
    "        super(DenseConv, self).__init__()\n",
    "    self.conv1 = nn.conv1d(in_channels = input_channel_size, out_channels = output_channel_size, kernel_size = 1, stride =1)\n",
    "    self.relu = nn.Relu()\n",
    "    def forward(self, inputs):\n",
    "        conv1d_outputs = self.relu(self.conv1(inputs))\n",
    "        return conv1d_outputs\n",
    "    \n",
    "def causalconv1(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size, kernel_size, stride, dilation):\n",
    "        super(causalconv1, self).__init__()\n",
    "        self.padding = (kernel_size-1)*dilation\n",
    "        self.dilationConv1d = nn.conv1d(in_channels = input_channel_size, out_channels = output_channel_size, \\\n",
    "                                    kernel_size = kernel_size, stride =stride, padding = self.padding, dilation= dilation)\n",
    "    def forward(self, inputs):\n",
    "        causal_conv1d_outputs = self.dilationConv1d(inputs)[:,:,:-self.padding[0]]\n",
    "        return causal_conv1d_outputs\n",
    "        \n",
    "def temporalConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size, intermediate_channel_size, kernel_size, stride, dilation):\n",
    "        super(causalconv1, self).__init__()\n",
    "        self.conv_dense_pre = DenseConv(input_channel_size, output_channel_size)\n",
    "        self.filter = causalconv1(output_channel_size, intermediate_channel_size, kernel_size, stride, dilation)  \n",
    "        self.gate = causalconv1(output_channel_size, intermediate_channel_size, kernel_size, stride, dilation) \n",
    "        self.conv_dense_post = DenseConv(intermediate_channel_size, output_channel_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.Relu()\n",
    "    def forward(self, inputs):\n",
    "        outputs_pre = self.conv_dense_pre(inputs)\n",
    "        outputs_filter = self.filter(outputs)\n",
    "        outputs_gate = self.filter(outputs)\n",
    "        outputs_post = self.tanh(outputs_filter) * self.tanh(outputs_gate)\n",
    "        outputs_post = self.conv_dense_post(outputs_post)\n",
    "        outputs = outputs_pre + outputs_post\n",
    "        return outputs, outputs_post\n",
    "        \n",
    "def temporalConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size, \\\n",
    "                 intermediate_channel_size, post_channel_size,kernel_size, stride, dilation, device):\n",
    "        super(causalconv1, self).__init__()\n",
    "        ### N层temporalConv，需要将其size写清楚：\n",
    "        self.tcn_list = nn.ModuleList([temporalConv(input_channel_size, output_channel_size, \\\n",
    "                                               intermediate_channel_size, kernel_size, stride, dilation)])\n",
    "        for i in dilation_list:\n",
    "            self.tcn_list.append(temporalConv(output_channel_size, output_channel_size, \\\n",
    "                                               intermediate_channel_size, kernel_size, stride, dilation))\n",
    "        self.conv_post = nn.Sequential(DenseConv(output_channel_size, post_channel_size),\n",
    "                                      nn.Dropout(0.2),\n",
    "                                      DenseConv(post_channel_size,1))\n",
    "            \n",
    "    def forward_t(self,inputs):\n",
    "        outputs_post_list = []\n",
    "        for tcn in self.tcn_list:\n",
    "            outputs, outputs_post = tcn(inputs)\n",
    "            inputs = outputs\n",
    "            outputs_post_list.append(outputs_post)\n",
    "        sum_outputs_post = sum(outputs_post_list)\n",
    "        outputs = self.conv_post(sum_outputs_post)\n",
    "        return outputs    \n",
    "        \n",
    "    def forward(self, inputs, teacher_forcing_rate):\n",
    "        if teacher_forcing_rate == 1:\n",
    "            outputs = self.forward_t(inputs)\n",
    "            return outputs[:, :-self.decoder_seq_len, :]\n",
    "        \n",
    "        else:\n",
    "            batch_size = inputs.size(0)\n",
    "            decoder_inputs = inputs[:, :, :-self.decoder_seq_len+1].clone()\n",
    "            decoder_outputs = torch.zeros(batch_size, decoder_inputs, device = self.device)\n",
    "            \n",
    "            for i in range(self.decoder_seq_len):\n",
    "                outputs = self.forward_t(decoder_inputs)[:,:,-1:] ### [129, 22, decoder_size]\n",
    "                decoder_exog = inputs[:,1:,-self.decoder_seq_len+1+i:] ### [129, 22-1, decoder_size]\n",
    "                decoder_exog = torch.cat([outputs,decoder_exog],dim=1)\n",
    "                decoder_inputs = torch.cat([decoder_inputs[:,:,1:], decoder_exog], dim =2 )\n",
    "            return decoder_outputs.unsqueeze(2)\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Applies a 1D convolution over an input signal composed of several input\n",
       "planes.\n",
       "\n",
       "In the simplest case, the output value of the layer with input size\n",
       ":math:`(N, C_{in}, L)` and output :math:`(N, C_{out}, L_{out})` can be\n",
       "precisely described as:\n",
       "\n",
       ".. math::\n",
       "\n",
       "    \\begin{equation*}\n",
       "    \\text{out}(N_i, C_{out_j}) = \\text{bias}(C_{out_j}) +\n",
       "                            \\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{out_j}, k) \\star \\text{input}(N_i, k)\n",
       "    \\end{equation*},\n",
       "\n",
       "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
       ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
       ":math:`L` is a length of signal sequence.\n",
       "\n",
       "* :attr:`stride` controls the stride for the cross-correlation, a single\n",
       "  number or a one-element tuple.\n",
       "\n",
       "* :attr:`padding` controls the amount of implicit zero-paddings on both sides\n",
       "  for :attr:`padding` number of points.\n",
       "\n",
       "* :attr:`dilation` controls the spacing between the kernel points; also\n",
       "  known as the à trous algorithm. It is harder to describe, but this `link`_\n",
       "  has a nice visualization of what :attr:`dilation` does.\n",
       "\n",
       "* :attr:`groups` controls the connections between inputs and outputs.\n",
       "  :attr:`in_channels` and :attr:`out_channels` must both be divisible by\n",
       "  :attr:`groups`. For example,\n",
       "\n",
       "    * At groups=1, all inputs are convolved to all outputs.\n",
       "    * At groups=2, the operation becomes equivalent to having two conv\n",
       "      layers side by side, each seeing half the input channels,\n",
       "      and producing half the output channels, and both subsequently\n",
       "      concatenated.\n",
       "    * At groups= :attr:`in_channels`, each input channel is convolved with\n",
       "      its own set of filters (of size\n",
       "      :math:`\\left\\lfloor \\frac{\\text{out_channels}}{\\text{in_channels}} \\right\\rfloor`).\n",
       "\n",
       ".. note::\n",
       "\n",
       "     Depending of the size of your kernel, several (of the last)\n",
       "     columns of the input might be lost, because it is a valid\n",
       "     `cross-correlation`_, and not a full `cross-correlation`_.\n",
       "     It is up to the user to add proper padding.\n",
       "\n",
       ".. note::\n",
       "\n",
       "     The configuration when `groups == in_channels` and `out_channels == K * in_channels`\n",
       "     where `K` is a positive integer is termed in literature as depthwise convolution.\n",
       "\n",
       "     In other words, for an input of size :math:`(N, C_{in}, L_{in})`, if you want a\n",
       "     depthwise convolution with a depthwise multiplier `K`,\n",
       "     then you use the constructor arguments\n",
       "     :math:`(\\text{in_channels}=C_{in}, \\text{out_channels}=C_{in} * K, ..., \\text{groups}=C_{in})`\n",
       "\n",
       "Args:\n",
       "    in_channels (int): Number of channels in the input image\n",
       "    out_channels (int): Number of channels produced by the convolution\n",
       "    kernel_size (int or tuple): Size of the convolving kernel\n",
       "    stride (int or tuple, optional): Stride of the convolution. Default: 1\n",
       "    padding (int or tuple, optional): Zero-padding added to both sides of\n",
       "        the input. Default: 0\n",
       "    dilation (int or tuple, optional): Spacing between kernel\n",
       "        elements. Default: 1\n",
       "    groups (int, optional): Number of blocked connections from input\n",
       "        channels to output channels. Default: 1\n",
       "    bias (bool, optional): If ``True``, adds a learnable bias to the output. Default: ``True``\n",
       "\n",
       "Shape:\n",
       "    - Input: :math:`(N, C_{in}, L_{in})`\n",
       "    - Output: :math:`(N, C_{out}, L_{out})` where\n",
       "\n",
       "      .. math::\n",
       "          L_{out} = \\left\\lfloor\\frac{L_{in} + 2 \\times \\text{padding} - \\text{dilation}\n",
       "                    \\times (\\text{kernel_size} - 1) - 1}{\\text{stride}} + 1\\right\\rfloor\n",
       "\n",
       "Attributes:\n",
       "    weight (Tensor): the learnable weights of the module of shape\n",
       "        (out_channels, in_channels, kernel_size)\n",
       "    bias (Tensor):   the learnable bias of the module of shape\n",
       "        (out_channels)\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> m = nn.Conv1d(16, 33, 3, stride=2)\n",
       "    >>> input = torch.randn(20, 16, 50)\n",
       "    >>> output = m(input)\n",
       "\n",
       ".. _cross-correlation:\n",
       "    https://en.wikipedia.org/wiki/Cross-correlation\n",
       "\n",
       ".. _link:\n",
       "    https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
       "\u001b[0;31mFile:\u001b[0m           /usr/local/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.Conv1d?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
