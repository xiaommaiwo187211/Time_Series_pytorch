{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, Sampler, DataLoader, WeightedRandomSampler, RandomSampler\n",
    "\n",
    "\n",
    "class TimeSeriesDataSet(Dataset):\n",
    "    def __init__(self, data_path, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.encoder_inputs = np.load(data_path + 'train_encoder_inputs_exog.npy')\n",
    "            self.decoder_targets = np.load(data_path + 'train_decoder_targets_exog.npy')\n",
    "        else:\n",
    "            self.encoder_inputs = np.load(data_path + 'test_encoder_inputs_exog.npy')\n",
    "            self.decoder_targets = np.load(data_path + 'test_decoder_targets_exog.npy')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoder_inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return item, self.encoder_inputs[item, :], self.decoder_targets[item, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "class DenseConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size):\n",
    "        super(DenseConv, self).__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv1d(in_channels = input_channel_size, out_channels = output_channel_size, kernel_size = 1, stride =1)\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, inputs):\n",
    "        conv1d_outputs = self.relu(self.conv1(inputs))\n",
    "        return conv1d_outputs\n",
    "    \n",
    "class CausalDilatedConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size, kernel_size=2, dilation=1):\n",
    "        super(CausalDilatedConv, self).__init__()\n",
    "        self.padding = (kernel_size-1)*dilation\n",
    "        self.CausalDilatedConv = nn.Conv1d(in_channels = input_channel_size, out_channels = output_channel_size, \\\n",
    "                                    kernel_size = kernel_size, stride =1, padding = self.padding, dilation= dilation)\n",
    "    def forward(self, inputs):\n",
    "#         import pdb;pdb.set_trace()\n",
    "        causal_conv1d_outputs = self.CausalDilatedConv(inputs)[:,:,:-self.padding]\n",
    "        return causal_conv1d_outputs\n",
    "        \n",
    "class TemporalConv(nn.Module):\n",
    "    def __init__(self, input_channel_size, output_channel_size, intermediate_channel_size, kernel_size, dilation):\n",
    "        super(TemporalConv, self).__init__()\n",
    "        self.conv_dense_pre = DenseConv(input_channel_size, output_channel_size)\n",
    "        self.filter = CausalDilatedConv(output_channel_size, intermediate_channel_size, kernel_size, dilation)  \n",
    "        self.gate = CausalDilatedConv(output_channel_size, intermediate_channel_size, kernel_size, dilation) \n",
    "        self.conv_dense_post = DenseConv(intermediate_channel_size, output_channel_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "    def forward(self, inputs):\n",
    "        outputs_pre = self.conv_dense_pre(inputs)\n",
    "        outputs_filter = self.filter(outputs_pre)\n",
    "        outputs_gate = self.filter(outputs_pre)\n",
    "        outputs_post = self.tanh(outputs_filter) * self.tanh(outputs_gate)\n",
    "        outputs_post = self.conv_dense_post(outputs_post)\n",
    "        outputs = outputs_pre + outputs_post\n",
    "        return outputs, outputs_post\n",
    "        \n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, encoder_seq_len, decoder_seq_len, input_channel_size, output_channel_size, \\\n",
    "                 intermediate_channel_size,kernel_size, dilation_list,post_channel_size,dropout, device):\n",
    "        super(WaveNet, self).__init__()\n",
    "        self.decoder_seq_len = decoder_seq_len\n",
    "        self.encoder_seq_len = encoder_seq_len\n",
    "        self.device = device\n",
    "        ### N层temporalConv，需要将其size写清楚：\n",
    "        self.tcn_list = nn.ModuleList([TemporalConv(input_channel_size, output_channel_size, \\\n",
    "                                               intermediate_channel_size, kernel_size, dilation=1)])\n",
    "        for dilation in dilation_list[1:]:\n",
    "            self.tcn_list.append(TemporalConv(output_channel_size, output_channel_size, \\\n",
    "                                               intermediate_channel_size, kernel_size, dilation))\n",
    "        self.conv_post = nn.Sequential(DenseConv(output_channel_size, post_channel_size),\n",
    "                                      nn.Dropout(0.2),\n",
    "                                      DenseConv(post_channel_size,1))\n",
    "            \n",
    "    def forward_t(self,inputs):\n",
    "        outputs_post_list = []\n",
    "        for tcn in self.tcn_list:\n",
    "            outputs, outputs_post = tcn(inputs)\n",
    "            inputs = outputs\n",
    "            outputs_post_list.append(outputs_post)\n",
    "        sum_outputs_post = sum(outputs_post_list)\n",
    "        outputs = self.conv_post(sum_outputs_post)\n",
    "        return outputs    \n",
    "        \n",
    "    def forward(self, inputs, teacher_forcing_ratio):\n",
    "        if teacher_forcing_ratio == 1:\n",
    "            outputs = self.forward_t(inputs).permute(0,2,1)\n",
    "            return outputs[:, -self.decoder_seq_len:, :]\n",
    "        \n",
    "        else:\n",
    "            batch_size = inputs.size(0)\n",
    "            decoder_inputs = inputs[:, :, :-self.decoder_seq_len+1].clone()\n",
    "            decoder_outputs = torch.zeros(batch_size, self.decoder_seq_len, device = self.device)\n",
    "            \n",
    "            for i in range(self.decoder_seq_len):\n",
    "                outputs = self.forward_t(decoder_inputs)[:,:,-1:] ### [129, 22, decoder_size]\n",
    "                decoder_exog = inputs[:,1:,-self.decoder_seq_len+1+i].unsqueeze(2) ### [129, 22-1, decoder_size]                \n",
    "                decoder_exog = torch.cat([outputs,decoder_exog],dim=1)\n",
    "                decoder_inputs = torch.cat([decoder_inputs[:,:,1:], decoder_exog], dim =2)\n",
    "                decoder_outputs[:,i] = outputs.squeeze(2).squeeze(1)\n",
    "            return decoder_outputs.unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'\n",
    "DATA_PATH = 'data/'\n",
    "ENCODER_SEQ_LEN = 430\n",
    "DECODER_SEQ_LEN = 60\n",
    "BATCH_SIZE = 128\n",
    "BATCH_SIZE_TEST = 1024\n",
    "EPOCH_NUM = 100\n",
    "LEARNING_RATE = 0.001\n",
    "INPUT_CHANNEL_SIZE = 22\n",
    "OUTPUT_CHANNEL_SIZE = 32\n",
    "INTERMEDIATE_CHANNEL_SIZE = 32\n",
    "POST_CHANNEL_SIZE = 128\n",
    "HIDDEN_SIZE = 128\n",
    "DROPOUT = 0.2\n",
    "KERNEL_SIZE = 2\n",
    "DILATION_LIST = [1, 2, 4, 8]\n",
    "\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "train_dataset = TimeSeriesDataSet(data_path,mode='train')\n",
    "test_dataset = TimeSeriesDataSet(data_path,mode='test')\n",
    "trian_sampler = RandomSampler(train_dataset)\n",
    "test_sampler = RandomSampler(test_dataset)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, sampler = trian_sampler, drop_last = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = BATCH_SIZE, sampler = test_sampler, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.5201876596097024\n",
      "test_loss 0.5270009463833224\n",
      "train_loss 0.41802334112505757\n",
      "test_loss 0.49892126264110687\n",
      "train_loss 0.3961267855859572\n",
      "test_loss 0.4927492930043128\n",
      "train_loss 0.3929706629245512\n",
      "test_loss 0.4808902346318768\n",
      "train_loss 0.3924235941902284\n",
      "test_loss 0.48891660090415706\n",
      "train_loss 0.39163795209700064\n",
      "test_loss 0.47565070756020084\n",
      "train_loss 0.3910533026341469\n",
      "test_loss 0.4667402265533324\n",
      "train_loss 0.3903825782960461\n",
      "test_loss 0.47121471839566387\n",
      "train_loss 0.39026661938236606\n",
      "test_loss 0.4697215989712746\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "seq2seq = WaveNet(ENCODER_SEQ_LEN, DECODER_SEQ_LEN, INPUT_CHANNEL_SIZE, OUTPUT_CHANNEL_SIZE,\n",
    "                      INTERMEDIATE_CHANNEL_SIZE, KERNEL_SIZE, DILATION_LIST, POST_CHANNEL_SIZE, DROPOUT, device).to(device)\n",
    "\n",
    "\n",
    "loss_func = nn.L1Loss(reduction = 'elementwise_mean')\n",
    "optimize = optim.Adam(seq2seq.parameters(), lr = LEARNING_RATE, )\n",
    "\n",
    "def train_epoch(model, train_loader, loss_func, optimize):\n",
    "    model.train()\n",
    "    epoch_loss, total_num = 0, 0 \n",
    "    for step, (index,train_features, train_label) in enumerate(train_loader):\n",
    "        optimize.zero_grad()\n",
    "        train_features = train_features.float().to(device).permute(0,2,1)\n",
    "        outputs = model(train_features, teacher_forcing_ratio=1)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        loss = loss_func(outputs.contiguous().view(-1), train_label.view(-1).float())\n",
    "        loss.backward()\n",
    "        optimize.step()\n",
    "#         import pdb; pdb.set_trace()\n",
    "        epoch_loss =epoch_loss + loss.item() * outputs.contiguous().view(-1).size(0)\n",
    "        total_num = total_num + outputs.contiguous().view(-1).size(0)\n",
    "    return epoch_loss/total_num\n",
    "        \n",
    "def test_epoch(model, test_loader,loss_func):\n",
    "    model.eval()\n",
    "    epoch_loss_test, total_num = 0 , 0\n",
    "    for step, (index,test_features, test_label) in enumerate(test_loader):\n",
    "#         import pdb; pdb.set_trace()\n",
    "        outputs = model(test_features.permute(0,2,1).float().to(device), teacher_forcing_ratio = 0)\n",
    "        loss = loss_func(outputs.contiguous().view(-1), test_label.view(-1).float().to(device))\n",
    "        epoch_loss_test = epoch_loss_test + loss.item() * outputs.contiguous().view(-1).size(0)\n",
    "        total_num = total_num + outputs.contiguous().view(-1).size(0)\n",
    "    return epoch_loss_test/total_num\n",
    "    \n",
    "    \n",
    "for i in range(EPOCH_NUM):\n",
    "    train_loss = train_epoch(seq2seq, train_loader, loss_func, optimize)\n",
    "    test_loss = test_epoch(seq2seq, test_loader,loss_func)\n",
    "    print('train_loss', train_loss)\n",
    "    print('test_loss', test_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ math::\n",
    "    \\ell(x, y) = \\begin{cases}\n",
    "        \\operatorname{mean}(L), & \\text{if}\\; \\text{size_average} = \\text{True},\\\\\n",
    "        \\operatorname{sum}(L),  & \\text{if}\\; \\text{size_average} = \\text{False}.\n",
    "    \\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, loss_func, device):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss, total_num = 0, 0\n",
    "    for i, (_, encoder_inputs, decoder_targets) in enumerate(data_loader):\n",
    "        # encoder_inputs: (batch, 1, total_sequence)\n",
    "        # decoder_targets: (batch, decoder_sequence, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        encoder_inputs = encoder_inputs.float().to(device).permute(0, 2, 1)\n",
    "        decoder_targets = decoder_targets.float().to(device)\n",
    "\n",
    "        model_outputs = model(encoder_inputs, teacher_forcing_ratio=1)\n",
    "#         import pdb; pdb.set_trace()\n",
    "        loss, cnt = loss_func(model_outputs.contiguous().view(-1), decoder_targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * cnt\n",
    "        total_num += cnt\n",
    "\n",
    "    return epoch_loss / total_num\n",
    "\n",
    "\n",
    "def evaluate_epoch(model, data_loader, loss_func, device):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss, total_num = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for i, (_, encoder_inputs, decoder_targets) in enumerate(data_loader):\n",
    "            # encoder_inputs: (batch, 1, encoder_sequence)\n",
    "            # decoder_targets: (batch, decoder_sequence, 1)\n",
    "\n",
    "            encoder_inputs = encoder_inputs.float().to(device).permute(0, 2, 1)\n",
    "            decoder_targets = decoder_targets.float().to(device)\n",
    "\n",
    "            model_outputs = model(encoder_inputs, teacher_forcing_ratio=0)\n",
    "            loss, cnt = loss_func(model_outputs.contiguous().view(-1), decoder_targets.view(-1))\n",
    "            epoch_loss += loss.item() * cnt\n",
    "            total_num += cnt\n",
    "\n",
    "    return epoch_loss / total_num\n",
    "\n",
    "\n",
    "def mae_loss(outputs, targets, reduction='elementwise_mean'):\n",
    "    mae = nn.L1Loss(reduction=reduction)\n",
    "    return mae(outputs, targets), outputs.numel()\n",
    "\n",
    "\n",
    "def save_embedding(target):\n",
    "    embedding_weights = eval('seq2seq.embedding_' + target + '.weight.data.cpu().numpy()')\n",
    "    embedding_index = eval('train_set.' + target + '_arr')\n",
    "    embedding = np.concatenate([embedding_index.reshape((-1, 1)), embedding_weights], axis=1)\n",
    "    np.save('model/' + target + '_embedding.npy', embedding)\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if len(param.data.size()) > 1:\n",
    "            nn.init.kaiming_normal_(param.data)\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "\n",
    "def set_seed():\n",
    "    SEED = 1\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    DATA_PATH = 'data/'\n",
    "    ENCODER_SEQ_LEN = 430\n",
    "    DECODER_SEQ_LEN = 60\n",
    "    BATCH_SIZE = 128\n",
    "    BATCH_SIZE_TEST = 1024\n",
    "    EPOCH_NUM = 100\n",
    "    LEARNING_RATE = 0.001\n",
    "    INPUT_CHANNEL_SIZE = 22\n",
    "    OUTPUT_CHANNEL_SIZE = 32\n",
    "    INTERMEDIATE_CHANNEL_SIZE = 38\n",
    "    POST_CHANNEL_SIZE = 142\n",
    "    HIDDEN_SIZE = 128\n",
    "    DROPOUT = 0.2\n",
    "    KERNEL_SIZE = 2\n",
    "    DILATION_LIST = [1, 2, 4, 8]\n",
    "\n",
    "    set_seed()\n",
    "\n",
    "    # device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "    train_set = TimeSeriesDataSet(DATA_PATH, mode='train')\n",
    "    test_set = TimeSeriesDataSet(DATA_PATH, mode='test')\n",
    "    train_sampler = RandomSampler(train_set)\n",
    "    test_sampler = RandomSampler(test_set)\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=0)\n",
    "    test_loader = DataLoader(test_set, batch_size=BATCH_SIZE_TEST, sampler=test_sampler, num_workers=0)\n",
    "\n",
    "    seq2seq = WaveNet(ENCODER_SEQ_LEN, DECODER_SEQ_LEN, INPUT_CHANNEL_SIZE, OUTPUT_CHANNEL_SIZE,\n",
    "                      INTERMEDIATE_CHANNEL_SIZE, KERNEL_SIZE, DILATION_LIST, POST_CHANNEL_SIZE, DROPOUT, device).to(device)\n",
    "\n",
    "    seq2seq.apply(init_weights)\n",
    "\n",
    "    optimizer = optim.Adam(seq2seq.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    min_val_loss = float('inf')\n",
    "    not_descending_cnt = 0\n",
    "    for epoch in range(EPOCH_NUM):\n",
    "\n",
    "        start_time = time()\n",
    "\n",
    "        train_loss = train_epoch(seq2seq, train_loader, optimizer, mae_loss, device)\n",
    "\n",
    "#         val_loss = evaluate_epoch(seq2seq, test_loader, mae_loss, device)\n",
    "\n",
    "#         end_time = time()\n",
    "\n",
    "#         epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "#         print('Epoch: %s | Time: %sm %ss' % (str(epoch + 1).zfill(2), epoch_mins, epoch_secs))\n",
    "#         print('\\tTrain Loss: %.3f | Val Loss: %.3f' % (train_loss, val_loss))\n",
    "\n",
    "#         if val_loss >= min_val_loss:\n",
    "#             not_descending_cnt += 1\n",
    "#             if not_descending_cnt >= 20 and epoch >= 19 and epoch != EPOCH_NUM - 1:\n",
    "#                 print('Early Stopped ...')\n",
    "#                 break\n",
    "#         else:\n",
    "#             not_descending_cnt = 0\n",
    "#             if epoch >= 2:\n",
    "#                 min_val_loss = val_loss\n",
    "#                 torch.save(seq2seq.state_dict(), 'model/wavenet_model.pt')\n",
    "#                 print()\n",
    "#                 print('model saved with validation loss', val_loss)\n",
    "#                 print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import das.udf.estimator as de\n",
    "u_job= de.Udf(entry_point = '/mnt/xiaoxiao10/pytorch/wavenet_all/train_evaluate.py', \\\n",
    "              image_name = 'repo.jd.local/public/notebook:nb5.5-pytorch0.4-py3-gpu', \\\n",
    "              train_gpu_count = 1)\n",
    "u_job.fit(base_job_name='pytorch-ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
